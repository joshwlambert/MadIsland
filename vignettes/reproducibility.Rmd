---
title: "Reproducibility"
output: rmarkdown::html_document
vignette: >
  %\VignetteIndexEntry{Reproducibility}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

This vignette is a guide to reproducing the data and results in the Madagascar terrestrial vertebrate paper.

The vignette goes step-by-step to extract data, run the analysis and then make the plots and summary statistics. Certain parts are computationally intensive and require a High Performance Cluster Computer (HPCC). In our case we run on the Hábrók HPCC. Other parts that can be run on a local machine (i.e. laptop) or on the HPCC have tabs detailing the different approaches. Fundamentally, they both run the same code, but the HPCC requires bash scripts and some maneuvering around the working directory.

## Install {.tabset}

### Local

Clone the `MadIsland` repository onto your machine. Once it is cloned, install the package using `devtools::install()` (this requires being in the root directory of the `MadIsland` package as the working directory).

Next restore the packages to their version using in the manuscript using `renv::restore()`.

### HPCC

Clone the DAISIEutils R package and the MadIsland R package in the home working directory. Here the home working directory refers to home/p-number/. 

Then change directory into MadIsland (`cd MadIsland`). Run the install bash script to ensure MadIsland is installed on the cluster (`sbatch inst/bash/install/install_MadIsland.sh`). 

## {-}

## Extract island community data {.tabset}

### Local

Each of the extraction scripts can be run by entering the following into the R console:

* `source(file.path("inst", "scripts", "extract_data", "amp", "extract_amp_complete_ds_asr.R"))`
* `source(file.path("inst", "scripts", "extract_data", "amp", "extract_amp_dna_ds_asr.R"))`
* `source(file.path("inst", "scripts", "extract_data", "bird", "extract_bird_complete_ds_asr.R"))`
* `source(file.path("inst", "scripts", "extract_data", "bird", "extract_bird_dna_ds_asr.R"))`
* `source(file.path("inst", "scripts", "extract_data", "nvm", "extract_nvm_complet_ds_asr.R"))`
* `source(file.path("inst", "scripts", "extract_data", "nvm", "extract_nvm_complete_ds_asr.R"))`
* `source(file.path("inst", "scripts", "extract_data", "nvm", "extract_nvm_dna_ds_asr.R"))`
* `source(file.path("inst", "scripts", "extract_data", "squa", "extract_squa_complete_ds_asr.R"))`
* `source(file.path("inst", "scripts", "extract_data", "squa", "extract_squa_dna_ds_asr.R"))`
* `source(file.path("inst", "scripts", "extract_data", "vm", "extract_vm_complete_ds_asr.R"))`
* `source(file.path("inst", "scripts", "extract_data", "vm", "extract_vm_dna_ds_asr.R"))`

### HPCC

Run the extraction scripts with `MadIsland` as the working directory due to the file paths for saving, for compatibility with running the scripts locally (e.g. within Rstudio). The other option would be to have a platform identifier (e.g. `.Platform$OS.type`) to determine the file path. However, this platform specific option prevents reproducibility for those running the scripts locally on a Mac or Linux machine (because `.Platform$OS.type == "unix"` in those cases). The logs folder is already present at this point as it is made in the install of MadIsland, but good to check that the logs folder is in `MadIsland`. 

Run each of the extraction scripts from `MadIsland` to produce the extracted data:

  * `sbatch inst/bash/extract_data/amp/extract_amp_complete_ds_asr.sh`
  * `sbatch inst/bash/extract_data/amp/extract_amp_dna_ds_asr.sh`
  * `sbatch inst/bash/extract_data/bird/extract_bird_complete_ds_asr.sh`
  * `sbatch inst/bash/extract_data/bird/extract_bird_dna_ds_asr.sh`
  * `sbatch inst/bash/extract_data/nvm/extract_nvm_complete_ds_asr.sh`
  * `sbatch inst/bash/extract_data/nvm/extract_nvm_dna_ds_asr.sh`
  * `sbatch inst/bash/extract_data/vm/extract_vm_complete_ds_asr.sh`
  * `sbatch inst/bash/extract_data/vm/extract_vm_dna_ds_asr.sh`
  * `sbatch inst/bash/extract_data/squa/extract_squa_complete_ds_asr.sh`
  * `sbatch inst/bash/extract_data/squa/extract_squa_dna_ds_asr.sh`
  
## {-}

## Moving island community data {.tabset}

Now that the island community data has been extracted and can be used for fitting the DAISIE inference models there is one more preparation step. The `DAISIEutils` package loads data using the `data()` function and thus it cannot be loaded from within the `inst/` folder where the extracted data is currently stored. Therefore, the `data-raw` scripts need to be executed to move the data sets we are fitting DAISIE to across to data. All data-raw scripts read the extracted data from `inst/extdata/extracted_data/...` and save it as data to be read by `data()`. 

### Local

Run each of the `data-raw` scripts:

* `source(file.path("data-raw", "amp_ddl_complete_ds_asr.R"))`
* `source(file.path("data-raw", "amp_ddl_dna_ds_asr.R"))`
* `source(file.path("data-raw", "bird_ddl_complete_ds_asr.R"))`
* `source(file.path("data-raw", "bird_ddl_dna_ds_asr.R"))`
* `source(file.path("data-raw", "nvm_ddl_complete_ds_asr.R"))`
* `source(file.path("data-raw", "nvm_ddl_dna_ds_asr.R"))`
* `source(file.path("data-raw", "squa_ddl_complete_ds_asr.R"))`
* `source(file.path("data-raw", "squa_ddl_dna_ds_asr.R"))`
* `source(file.path("data-raw", "vm_ddl_complete_ds_asr.R"))`
* `source(file.path("data-raw", "vm_ddl_dna_ds_asr.R"))`

### HPCC

To do this step automatically run `sbatch inst/bash/move_data/move_data.sh`. 

## {-}

## Analysing data {.tabset}

### Local

This step cannot be run locally and requires using a HPCC. If you have been running things locally up to this point you need to clone your local `MadIsland` repository onto the HPCC to make sure all the data is available. 

`MadIsland` is setup to use the `DAISIEutils` package to run the DAISIE models on the data. See HPCC tab.

### HPCC

Before running the analyses, make sure a `logs/` folder is in the home directory. If this is not present create a logs folder.

Then to ensure the data is available reinstall the package in the home directory by opening R (`ml R` and then `R`) and reinstall the package (`devtools::install("MadIsland")`). Make sure this step is done in the home directory so the `MadIsland` package is installed on the general Hábrók system and not in the `renv` cache.

***Side note***: if `DAISIEprep` or `ggtree` (a dependency of `DAISIEprep`) have not been installed on the system before you may need to run:
``` r
install.packages("BiocManager")
BiocManager::install("ggtree")
install.packages("DAISIEprep")
```
then try reinstalling `MadIsland` (`devtools::install("MadIsland")`).

Run the analysis scripts the home working directory on the Hábrók HPCC. 
This is because `MadIsland` interacts with the `DAISIEutils` package to run the 
DAISIE maximum likelihood models.

Run each of the analysis scripts to produce the DAISIE model output (parameter
estimates and model likelihood and Bayesian Information Criterion):

  * `sbatch MadIsland/inst/bash/analyse_data/analyse_amp/submit_amp_complete_nonoceanic_cr_dd.sh`
  * `sbatch MadIsland/inst/bash/analyse_data/analyse_amp/submit_amp_dna_nonoceanic_cr_dd.sh`
  * `sbatch MadIsland/inst/bash/analyse_data/analyse_bird/submit_bird_complete_nonoceanic_cr_dd.sh`
  * `sbatch MadIsland/inst/bash/analyse_data/analyse_bird/submit_bird_dna_nonoceanic_cr_dd.sh`
  * `sbatch MadIsland/inst/bash/analyse_data/analyse_nvm/submit_nvm_complete_nonoceanic_cr_dd.sh`
  * `sbatch MadIsland/inst/bash/analyse_data/analyse_nvm/submit_nvm_dna_nonoceanic_cr_dd.sh`
  * `sbatch MadIsland/inst/bash/analyse_data/analyse_vm/submit_vm_complete_nonoceanic_cr_dd.sh`
  * `sbatch MadIsland/inst/bash/analyse_data/analyse_vm/submit_vm_dna_nonoceanic_cr_dd.sh`
  * `sbatch MadIsland/inst/bash/analyse_data/analyse_squa/submit_squa_complete_nonoceanic_cr_dd.sh`
  * `sbatch MadIsland/inst/bash/analyse_data/analyse_squa/submit_squa_dna_nonoceanic_cr_dd.sh`

## {-}

## Moving DAISIE results {.tabset}

### Local

This step is dependent on the previous analysing data step which required using the HPCC. This step also requires using the HPCC, see HPCC tab.

### HPCC

The results of fitting the DAISIE models to the data are saved in the `results/` folder in the home directory of the HPCC. The files need to be transferred, for which we use git. The DAISIE output files therefore need to be moved into a directory which has git initialised, we use the `MadIsland` directory and transfer the files into an existing folder called `raw_daisie_output/`. This can be done using the following:

* `cp -r results/amp_ddl_complete_ds_asr/ MadIsland/inst/extdata/raw_daisie_output/`
* `cp -r results/amp_ddl_dna_ds_asr/ MadIsland/inst/extdata/raw_daisie_output/`
* `cp -r results/bird_ddl_complete_ds_asr/ MadIsland/inst/extdata/raw_daisie_output/`
* `cp -r results/bird_ddl_dna_ds_asr/ MadIsland/inst/extdata/raw_daisie_output/`
* `cp -r results/nvm_ddl_complete_ds_asr/ MadIsland/inst/extdata/raw_daisie_output/`
* `cp -r results/nvm_ddl_dna_ds_asr/ MadIsland/inst/extdata/raw_daisie_output/`
* `cp -r results/squa_ddl_complete_ds_asr/ MadIsland/inst/extdata/raw_daisie_output/`
* `cp -r results/squa_ddl_dna_ds_asr/ MadIsland/inst/extdata/raw_daisie_output/`
* `cp -r results/vm_ddl_complete_ds_asr/ MadIsland/inst/extdata/raw_daisie_output/`
* `cp -r results/vm_ddl_dna_ds_asr/ MadIsland/inst/extdata/raw_daisie_output/`

Once the files are moved (technically they are copied) into `raw_daisie_output/` they can be commited and pushed (`git commit` & `git push`).

## {-}
